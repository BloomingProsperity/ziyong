# 14 - ç›‘æ§å‘Šè­¦æ¨¡å— (Monitoring & Alerting)

---
name: monitoring-alerting
version: 1.0.0
description: çˆ¬è™«è¿è¡Œç›‘æ§ã€æ€§èƒ½åˆ†æä¸å¼‚å¸¸å‘Šè­¦
triggers:
  - "ç›‘æ§"
  - "å‘Šè­¦"
  - "monitoring"
  - "alerting"
  - "metrics"
  - "æ—¥å¿—"
difficulty: â­â­â­
---

## æ¨¡å—ç›®æ ‡

**æ ¸å¿ƒåŸåˆ™ï¼šç»™å‡ºéœ€æ±‚ï¼Œå¿…é¡»å®Œæˆã€‚**

| ç›®æ ‡ | è¾¾æˆæ ‡å‡† |
|------|---------|
| **æŒ‡æ ‡å…¨é‡‡é›†** | è¯·æ±‚é‡/é”™è¯¯ç‡/å»¶è¿Ÿ/é˜Ÿåˆ—é•¿åº¦ç­‰æ ¸å¿ƒæŒ‡æ ‡å®æ—¶å¯è§ |
| **å‘Šè­¦åŠæ—¶** | å¼‚å¸¸å‘ç”Ÿå 1 åˆ†é’Ÿå†…è§¦å‘å‘Šè­¦ï¼Œé€šçŸ¥åˆ°ç›¸å…³äººå‘˜ |
| **æ—¥å¿—å¯æŸ¥** | ç»“æ„åŒ–æ—¥å¿—æ”¯æŒå¿«é€Ÿæ£€ç´¢å’Œé—®é¢˜å®šä½ |
| **é“¾è·¯å¯è¿½è¸ª** | åˆ†å¸ƒå¼åœºæ™¯ä¸‹è¯·æ±‚å…¨é“¾è·¯å¯è¿½æº¯ |
| **ä»ªè¡¨ç›˜ç›´è§‚** | Grafana ä»ªè¡¨ç›˜ä¸€ç›®äº†ç„¶ï¼Œå…³é”®æŒ‡æ ‡å¯è§†åŒ– |

---

## æ¨¡å—æ¦‚è¿°

ç›‘æ§å‘Šè­¦æ¨¡å—è´Ÿè´£å®æ—¶ç›‘æ§çˆ¬è™«è¿è¡ŒçŠ¶æ€ã€æ”¶é›†æ€§èƒ½æŒ‡æ ‡ã€åˆ†ææ—¥å¿—ã€åŠæ—¶å‘ç°é—®é¢˜å¹¶å‘Šè­¦ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç›‘æ§å‘Šè­¦æ¶æ„                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         æ•°æ®é‡‡é›†å±‚                                   â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚   â”‚  â”‚ æŒ‡æ ‡é‡‡é›†  â”‚ â”‚ æ—¥å¿—é‡‡é›†  â”‚ â”‚ é“¾è·¯è¿½è¸ª  â”‚ â”‚ å¥åº·æ£€æŸ¥  â”‚              â”‚  â”‚
â”‚   â”‚  â”‚Prometheusâ”‚ â”‚  Loki    â”‚ â”‚  Jaeger  â”‚ â”‚HealthChk â”‚              â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         å­˜å‚¨å±‚                                       â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚  â”‚
â”‚   â”‚  â”‚ æ—¶åºæ•°æ®åº“ â”‚ â”‚ æ—¥å¿—å­˜å‚¨  â”‚ â”‚ è¿½è¸ªå­˜å‚¨  â”‚                           â”‚  â”‚
â”‚   â”‚  â”‚   TSDB   â”‚ â”‚   ES    â”‚ â”‚  Jaeger  â”‚                           â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                         å±•ç¤ºä¸å‘Šè­¦å±‚                                  â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚   â”‚  â”‚ Grafana  â”‚ â”‚AlertMgr â”‚ â”‚ é’‰é’‰/é£ä¹¦ â”‚ â”‚  é‚®ä»¶    â”‚              â”‚  â”‚
â”‚   â”‚  â”‚  ä»ªè¡¨ç›˜   â”‚ â”‚ å‘Šè­¦è§„åˆ™  â”‚ â”‚  Webhook â”‚ â”‚  SMTP   â”‚              â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æŒ‡æ ‡é‡‡é›†

### Prometheus æŒ‡æ ‡

```python
"""
Prometheus æŒ‡æ ‡é‡‡é›†
"""

from prometheus_client import (
    Counter, Histogram, Gauge, Summary,
    CollectorRegistry, generate_latest, CONTENT_TYPE_LATEST,
    start_http_server
)
from functools import wraps
import time
from typing import Callable
from dataclasses import dataclass


# åˆ›å»ºæŒ‡æ ‡
class CrawlerMetrics:
    """çˆ¬è™«æŒ‡æ ‡"""

    def __init__(self, registry: CollectorRegistry = None):
        self.registry = registry or CollectorRegistry()

        # è¯·æ±‚è®¡æ•°å™¨
        self.requests_total = Counter(
            'crawler_requests_total',
            'Total number of HTTP requests',
            ['method', 'domain', 'status_code'],
            registry=self.registry
        )

        # è¯·æ±‚å»¶è¿Ÿç›´æ–¹å›¾
        self.request_duration = Histogram(
            'crawler_request_duration_seconds',
            'HTTP request duration in seconds',
            ['domain'],
            buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
            registry=self.registry
        )

        # æ´»è·ƒä»»åŠ¡æ•°
        self.active_tasks = Gauge(
            'crawler_active_tasks',
            'Number of active crawl tasks',
            ['worker_id'],
            registry=self.registry
        )

        # é˜Ÿåˆ—é•¿åº¦
        self.queue_size = Gauge(
            'crawler_queue_size',
            'Number of URLs in queue',
            ['queue_name'],
            registry=self.registry
        )

        # é”™è¯¯è®¡æ•°å™¨
        self.errors_total = Counter(
            'crawler_errors_total',
            'Total number of errors',
            ['error_type', 'domain'],
            registry=self.registry
        )

        # æ•°æ®é‡‡é›†é‡
        self.items_scraped = Counter(
            'crawler_items_scraped_total',
            'Total number of items scraped',
            ['spider', 'item_type'],
            registry=self.registry
        )

        # ä»£ç†ä½¿ç”¨æƒ…å†µ
        self.proxy_requests = Counter(
            'crawler_proxy_requests_total',
            'Total proxy requests',
            ['proxy', 'status'],
            registry=self.registry
        )

        # éªŒè¯ç é‡åˆ°æ¬¡æ•°
        self.captcha_encountered = Counter(
            'crawler_captcha_total',
            'Total captchas encountered',
            ['domain', 'captcha_type'],
            registry=self.registry
        )

        # å†…å­˜ä½¿ç”¨
        self.memory_usage = Gauge(
            'crawler_memory_bytes',
            'Memory usage in bytes',
            ['type'],
            registry=self.registry
        )

        # å“åº”å¤§å°
        self.response_size = Summary(
            'crawler_response_size_bytes',
            'Response size in bytes',
            ['domain'],
            registry=self.registry
        )

    def record_request(
        self,
        domain: str,
        method: str,
        status_code: int,
        duration: float,
        response_size: int
    ):
        """è®°å½•è¯·æ±‚"""
        self.requests_total.labels(
            method=method,
            domain=domain,
            status_code=str(status_code)
        ).inc()

        self.request_duration.labels(domain=domain).observe(duration)
        self.response_size.labels(domain=domain).observe(response_size)

    def record_error(self, error_type: str, domain: str):
        """è®°å½•é”™è¯¯"""
        self.errors_total.labels(error_type=error_type, domain=domain).inc()

    def record_item(self, spider: str, item_type: str, count: int = 1):
        """è®°å½•é‡‡é›†é¡¹"""
        self.items_scraped.labels(spider=spider, item_type=item_type).inc(count)


# è£…é¥°å™¨æ–¹å¼ä½¿ç”¨
def track_request(metrics: CrawlerMetrics, domain: str):
    """è¯·æ±‚è¿½è¸ªè£…é¥°å™¨"""

    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()

            try:
                response = await func(*args, **kwargs)
                duration = time.time() - start_time

                metrics.record_request(
                    domain=domain,
                    method=getattr(response, 'request', {}).get('method', 'GET'),
                    status_code=response.status_code,
                    duration=duration,
                    response_size=len(response.content)
                )

                return response

            except Exception as e:
                metrics.record_error(type(e).__name__, domain)
                raise

        return wrapper
    return decorator


# æŒ‡æ ‡æœåŠ¡å™¨
class MetricsServer:
    """æŒ‡æ ‡æš´éœ²æœåŠ¡"""

    def __init__(self, metrics: CrawlerMetrics, port: int = 9090):
        self.metrics = metrics
        self.port = port

    def start(self):
        """å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨"""
        start_http_server(self.port, registry=self.metrics.registry)
        print(f"Metrics server started on port {self.port}")

    def get_metrics(self) -> bytes:
        """è·å–æŒ‡æ ‡æ•°æ®"""
        return generate_latest(self.metrics.registry)


# ä½¿ç”¨ç¤ºä¾‹
metrics = CrawlerMetrics()
metrics_server = MetricsServer(metrics)
metrics_server.start()

# çˆ¬å–æ—¶è®°å½•
@track_request(metrics, "example.com")
async def fetch_page(url: str):
    import httpx
    async with httpx.AsyncClient() as client:
        return await client.get(url)
```

### è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†å™¨

```python
"""
è‡ªå®šä¹‰ Prometheus æ”¶é›†å™¨
"""

from prometheus_client.core import GaugeMetricFamily, CounterMetricFamily
from prometheus_client import CollectorRegistry, REGISTRY
import redis


class CrawlerStatsCollector:
    """çˆ¬è™«çŠ¶æ€æ”¶é›†å™¨"""

    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    def collect(self):
        """æ”¶é›†æŒ‡æ ‡"""

        # é˜Ÿåˆ—æŒ‡æ ‡
        queue_gauge = GaugeMetricFamily(
            'crawler_queue_length',
            'Length of crawler queues',
            labels=['queue']
        )

        queues = ['pending', 'processing', 'completed', 'failed']
        for queue in queues:
            length = self.redis.llen(f"crawler:{queue}")
            queue_gauge.add_metric([queue], length)

        yield queue_gauge

        # Worker çŠ¶æ€
        worker_gauge = GaugeMetricFamily(
            'crawler_workers',
            'Number of workers by status',
            labels=['status']
        )

        workers = self.redis.hgetall("crawler:workers")
        status_counts = {'idle': 0, 'busy': 0, 'error': 0}

        for worker_id, data in workers.items():
            import json
            info = json.loads(data)
            status = info.get('status', 'unknown')
            if status in status_counts:
                status_counts[status] += 1

        for status, count in status_counts.items():
            worker_gauge.add_metric([status], count)

        yield worker_gauge

        # ä»Šæ—¥ç»Ÿè®¡
        today_counter = CounterMetricFamily(
            'crawler_today_total',
            'Today statistics',
            labels=['metric']
        )

        today_stats = {
            'requests': self.redis.get("stats:today:requests") or 0,
            'success': self.redis.get("stats:today:success") or 0,
            'failed': self.redis.get("stats:today:failed") or 0,
            'items': self.redis.get("stats:today:items") or 0,
        }

        for metric, value in today_stats.items():
            today_counter.add_metric([metric], int(value))

        yield today_counter


# æ³¨å†Œæ”¶é›†å™¨
redis_client = redis.Redis()
REGISTRY.register(CrawlerStatsCollector(redis_client))
```

---

## æ—¥å¿—ç³»ç»Ÿ

### ç»“æ„åŒ–æ—¥å¿—

```python
"""
ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ
"""

import logging
import json
from datetime import datetime
from typing import Any, Dict
import sys
from dataclasses import dataclass, asdict
import traceback


class JsonFormatter(logging.Formatter):
    """JSON æ ¼å¼åŒ–å™¨"""

    def format(self, record: logging.LogRecord) -> str:
        log_data = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }

        # æ·»åŠ é¢å¤–å­—æ®µ
        if hasattr(record, 'extra_data'):
            log_data.update(record.extra_data)

        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__,
                "message": str(record.exc_info[1]),
                "traceback": traceback.format_exception(*record.exc_info)
            }

        return json.dumps(log_data, ensure_ascii=False)


class CrawlerLogger:
    """çˆ¬è™«æ—¥å¿—å™¨"""

    def __init__(
        self,
        name: str = "crawler",
        level: int = logging.INFO,
        json_output: bool = True
    ):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)

        # ç§»é™¤å·²æœ‰å¤„ç†å™¨
        self.logger.handlers = []

        # æ§åˆ¶å°å¤„ç†å™¨
        handler = logging.StreamHandler(sys.stdout)
        handler.setLevel(level)

        if json_output:
            handler.setFormatter(JsonFormatter())
        else:
            handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            ))

        self.logger.addHandler(handler)

    def _log(self, level: int, msg: str, **kwargs):
        """å†…éƒ¨æ—¥å¿—æ–¹æ³•"""
        extra = {'extra_data': kwargs} if kwargs else {}
        self.logger.log(level, msg, extra=extra)

    def debug(self, msg: str, **kwargs):
        self._log(logging.DEBUG, msg, **kwargs)

    def info(self, msg: str, **kwargs):
        self._log(logging.INFO, msg, **kwargs)

    def warning(self, msg: str, **kwargs):
        self._log(logging.WARNING, msg, **kwargs)

    def error(self, msg: str, **kwargs):
        self._log(logging.ERROR, msg, **kwargs)

    def exception(self, msg: str, **kwargs):
        self.logger.exception(msg, extra={'extra_data': kwargs})

    # çˆ¬è™«ä¸“ç”¨æ–¹æ³•
    def request(
        self,
        url: str,
        method: str,
        status_code: int,
        duration: float,
        **kwargs
    ):
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        self.info(
            f"HTTP {method} {url}",
            event="http_request",
            url=url,
            method=method,
            status_code=status_code,
            duration_ms=round(duration * 1000, 2),
            **kwargs
        )

    def item_scraped(self, item_type: str, item_id: str, **kwargs):
        """è®°å½•é‡‡é›†æ—¥å¿—"""
        self.info(
            f"Scraped {item_type}: {item_id}",
            event="item_scraped",
            item_type=item_type,
            item_id=item_id,
            **kwargs
        )

    def captcha(self, domain: str, captcha_type: str, success: bool, **kwargs):
        """è®°å½•éªŒè¯ç æ—¥å¿—"""
        self.info(
            f"Captcha {captcha_type} on {domain}: {'success' if success else 'failed'}",
            event="captcha",
            domain=domain,
            captcha_type=captcha_type,
            success=success,
            **kwargs
        )

    def proxy_error(self, proxy: str, error: str, **kwargs):
        """è®°å½•ä»£ç†é”™è¯¯"""
        self.warning(
            f"Proxy error: {proxy}",
            event="proxy_error",
            proxy=proxy,
            error=error,
            **kwargs
        )


# ä½¿ç”¨ç¤ºä¾‹
logger = CrawlerLogger("my_spider")

logger.request(
    url="https://example.com/api/products",
    method="GET",
    status_code=200,
    duration=0.235,
    proxy="http://proxy:8080"
)

logger.item_scraped(
    item_type="product",
    item_id="12345",
    title="Example Product",
    price=99.99
)
```

### æ—¥å¿—èšåˆ (Loki)

```python
"""
Loki æ—¥å¿—æ¨é€
"""

import httpx
import time
from typing import List, Dict
from dataclasses import dataclass
import json


@dataclass
class LokiConfig:
    url: str = "http://localhost:3100"
    batch_size: int = 100
    flush_interval: float = 5.0


class LokiHandler:
    """Loki æ—¥å¿—å¤„ç†å™¨"""

    def __init__(self, config: LokiConfig, labels: Dict[str, str]):
        self.config = config
        self.labels = labels
        self.buffer: List[tuple] = []
        self.last_flush = time.time()

    def push(self, message: str, level: str = "info", **extra_labels):
        """æ¨é€æ—¥å¿—"""

        timestamp = str(int(time.time() * 1e9))  # çº³ç§’æ—¶é—´æˆ³
        all_labels = {**self.labels, "level": level, **extra_labels}

        self.buffer.append((timestamp, message, all_labels))

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if len(self.buffer) >= self.config.batch_size:
            self.flush()
        elif time.time() - self.last_flush > self.config.flush_interval:
            self.flush()

    def flush(self):
        """åˆ·æ–°ç¼“å†²åŒºåˆ° Loki"""

        if not self.buffer:
            return

        # æŒ‰æ ‡ç­¾åˆ†ç»„
        streams = {}
        for timestamp, message, labels in self.buffer:
            label_key = json.dumps(labels, sort_keys=True)
            if label_key not in streams:
                streams[label_key] = {
                    "stream": labels,
                    "values": []
                }
            streams[label_key]["values"].append([timestamp, message])

        # æ„å»ºè¯·æ±‚ä½“
        payload = {"streams": list(streams.values())}

        # å‘é€åˆ° Loki
        try:
            httpx.post(
                f"{self.config.url}/loki/api/v1/push",
                json=payload,
                timeout=10
            )
        except Exception as e:
            print(f"Failed to push logs to Loki: {e}")

        self.buffer = []
        self.last_flush = time.time()


# é›†æˆåˆ° Python logging
import logging


class LokiLoggingHandler(logging.Handler):
    """Python logging çš„ Loki å¤„ç†å™¨"""

    def __init__(self, loki_handler: LokiHandler):
        super().__init__()
        self.loki = loki_handler

    def emit(self, record: logging.LogRecord):
        try:
            msg = self.format(record)
            extra = {}

            # æå–é¢å¤–å­—æ®µ
            if hasattr(record, 'extra_data'):
                for k, v in record.extra_data.items():
                    if isinstance(v, (str, int, float, bool)):
                        extra[k] = str(v)

            self.loki.push(msg, record.levelname.lower(), **extra)

        except Exception:
            self.handleError(record)


# ä½¿ç”¨ç¤ºä¾‹
loki_handler = LokiHandler(
    LokiConfig(url="http://localhost:3100"),
    labels={"job": "crawler", "env": "production"}
)

logger = logging.getLogger("crawler")
logger.addHandler(LokiLoggingHandler(loki_handler))
```

---

## å‘Šè­¦ç³»ç»Ÿ

### å‘Šè­¦è§„åˆ™

```python
"""
å‘Šè­¦è§„åˆ™å¼•æ“
"""

from dataclasses import dataclass, field
from typing import Callable, List, Dict, Any, Optional
from enum import Enum
from datetime import datetime, timedelta
import asyncio


class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    name: str
    description: str
    severity: AlertSeverity
    condition: Callable[[Dict], bool]
    cooldown: int = 300  # å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
    labels: Dict[str, str] = field(default_factory=dict)

    # è¿è¡Œæ—¶çŠ¶æ€
    last_triggered: Optional[datetime] = None
    is_firing: bool = False


@dataclass
class Alert:
    """å‘Šè­¦å®ä¾‹"""
    rule_name: str
    severity: AlertSeverity
    description: str
    labels: Dict[str, str]
    annotations: Dict[str, Any]
    starts_at: datetime
    ends_at: Optional[datetime] = None


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""

    def __init__(self):
        self.rules: List[AlertRule] = []
        self.active_alerts: Dict[str, Alert] = {}
        self.handlers: List[Callable[[Alert], None]] = []

    def add_rule(self, rule: AlertRule):
        """æ·»åŠ è§„åˆ™"""
        self.rules.append(rule)

    def add_handler(self, handler: Callable[[Alert], None]):
        """æ·»åŠ å‘Šè­¦å¤„ç†å™¨"""
        self.handlers.append(handler)

    def evaluate(self, metrics: Dict):
        """è¯„ä¼°æ‰€æœ‰è§„åˆ™"""

        now = datetime.now()

        for rule in self.rules:
            try:
                is_triggered = rule.condition(metrics)
            except Exception as e:
                print(f"Rule {rule.name} evaluation failed: {e}")
                continue

            alert_key = f"{rule.name}:{hash(frozenset(rule.labels.items()))}"

            if is_triggered:
                # æ£€æŸ¥å†·å´æ—¶é—´
                if rule.last_triggered:
                    if (now - rule.last_triggered).seconds < rule.cooldown:
                        continue

                if not rule.is_firing:
                    # æ–°å‘Šè­¦
                    alert = Alert(
                        rule_name=rule.name,
                        severity=rule.severity,
                        description=rule.description,
                        labels=rule.labels,
                        annotations={"metrics": metrics},
                        starts_at=now,
                    )
                    self.active_alerts[alert_key] = alert
                    rule.is_firing = True
                    rule.last_triggered = now

                    # è§¦å‘å¤„ç†å™¨
                    self._fire_alert(alert)

            else:
                if rule.is_firing:
                    # å‘Šè­¦æ¢å¤
                    if alert_key in self.active_alerts:
                        alert = self.active_alerts[alert_key]
                        alert.ends_at = now
                        self._resolve_alert(alert)
                        del self.active_alerts[alert_key]

                    rule.is_firing = False

    def _fire_alert(self, alert: Alert):
        """è§¦å‘å‘Šè­¦"""
        for handler in self.handlers:
            try:
                handler(alert)
            except Exception as e:
                print(f"Alert handler failed: {e}")

    def _resolve_alert(self, alert: Alert):
        """å‘Šè­¦æ¢å¤"""
        # å¯ä»¥å‘é€æ¢å¤é€šçŸ¥
        pass


# é¢„å®šä¹‰è§„åˆ™
def create_default_rules() -> List[AlertRule]:
    """åˆ›å»ºé»˜è®¤å‘Šè­¦è§„åˆ™"""

    return [
        AlertRule(
            name="high_error_rate",
            description="é”™è¯¯ç‡è¶…è¿‡ 10%",
            severity=AlertSeverity.CRITICAL,
            condition=lambda m: m.get("error_rate", 0) > 0.1,
            cooldown=300,
        ),
        AlertRule(
            name="queue_backlog",
            description="é˜Ÿåˆ—ç§¯å‹è¶…è¿‡ 10000",
            severity=AlertSeverity.WARNING,
            condition=lambda m: m.get("queue_size", 0) > 10000,
            cooldown=600,
        ),
        AlertRule(
            name="slow_response",
            description="å¹³å‡å“åº”æ—¶é—´è¶…è¿‡ 5 ç§’",
            severity=AlertSeverity.WARNING,
            condition=lambda m: m.get("avg_response_time", 0) > 5.0,
            cooldown=300,
        ),
        AlertRule(
            name="proxy_exhausted",
            description="å¯ç”¨ä»£ç†å°‘äº 5 ä¸ª",
            severity=AlertSeverity.CRITICAL,
            condition=lambda m: m.get("available_proxies", 100) < 5,
            cooldown=300,
        ),
        AlertRule(
            name="worker_down",
            description="æ´»è·ƒ Worker æ•°é‡ä¸º 0",
            severity=AlertSeverity.CRITICAL,
            condition=lambda m: m.get("active_workers", 1) == 0,
            cooldown=60,
        ),
        AlertRule(
            name="captcha_spike",
            description="éªŒè¯ç å‡ºç°ç‡è¶…è¿‡ 50%",
            severity=AlertSeverity.WARNING,
            condition=lambda m: m.get("captcha_rate", 0) > 0.5,
            cooldown=300,
        ),
    ]
```

### é€šçŸ¥æ¸ é“

```python
"""
å‘Šè­¦é€šçŸ¥æ¸ é“
"""

import httpx
from abc import ABC, abstractmethod
from typing import Dict
from dataclasses import dataclass
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart


class NotificationChannel(ABC):
    """é€šçŸ¥æ¸ é“åŸºç±»"""

    @abstractmethod
    def send(self, alert: Alert) -> bool:
        pass


class DingTalkChannel(NotificationChannel):
    """é’‰é’‰é€šçŸ¥"""

    def __init__(self, webhook_url: str, secret: str = None):
        self.webhook_url = webhook_url
        self.secret = secret

    def send(self, alert: Alert) -> bool:
        # é¢œè‰²æ˜ å°„
        colors = {
            AlertSeverity.INFO: "#1890ff",
            AlertSeverity.WARNING: "#faad14",
            AlertSeverity.CRITICAL: "#ff4d4f",
        }

        # æ„å»ºæ¶ˆæ¯
        message = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"[{alert.severity.value.upper()}] {alert.rule_name}",
                "text": f"""## ğŸš¨ çˆ¬è™«å‘Šè­¦

**è§„åˆ™**: {alert.rule_name}

**çº§åˆ«**: {alert.severity.value}

**æè¿°**: {alert.description}

**æ—¶é—´**: {alert.starts_at.strftime('%Y-%m-%d %H:%M:%S')}

**æ ‡ç­¾**: {', '.join(f'{k}={v}' for k, v in alert.labels.items())}
"""
            }
        }

        try:
            response = httpx.post(self.webhook_url, json=message, timeout=10)
            return response.status_code == 200
        except Exception as e:
            print(f"DingTalk notification failed: {e}")
            return False


class FeishuChannel(NotificationChannel):
    """é£ä¹¦é€šçŸ¥"""

    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url

    def send(self, alert: Alert) -> bool:
        message = {
            "msg_type": "interactive",
            "card": {
                "header": {
                    "title": {
                        "tag": "plain_text",
                        "content": f"[{alert.severity.value.upper()}] çˆ¬è™«å‘Šè­¦"
                    },
                    "template": "red" if alert.severity == AlertSeverity.CRITICAL else "orange"
                },
                "elements": [
                    {
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": f"""**è§„åˆ™**: {alert.rule_name}
**æè¿°**: {alert.description}
**æ—¶é—´**: {alert.starts_at.strftime('%Y-%m-%d %H:%M:%S')}"""
                        }
                    }
                ]
            }
        }

        try:
            response = httpx.post(self.webhook_url, json=message, timeout=10)
            return response.status_code == 200
        except Exception as e:
            print(f"Feishu notification failed: {e}")
            return False


class EmailChannel(NotificationChannel):
    """é‚®ä»¶é€šçŸ¥"""

    def __init__(
        self,
        smtp_host: str,
        smtp_port: int,
        username: str,
        password: str,
        from_addr: str,
        to_addrs: List[str]
    ):
        self.smtp_host = smtp_host
        self.smtp_port = smtp_port
        self.username = username
        self.password = password
        self.from_addr = from_addr
        self.to_addrs = to_addrs

    def send(self, alert: Alert) -> bool:
        subject = f"[{alert.severity.value.upper()}] çˆ¬è™«å‘Šè­¦: {alert.rule_name}"

        body = f"""
        <html>
        <body>
        <h2>ğŸš¨ çˆ¬è™«å‘Šè­¦</h2>
        <table border="1" cellpadding="10">
            <tr><td><b>è§„åˆ™</b></td><td>{alert.rule_name}</td></tr>
            <tr><td><b>çº§åˆ«</b></td><td>{alert.severity.value}</td></tr>
            <tr><td><b>æè¿°</b></td><td>{alert.description}</td></tr>
            <tr><td><b>æ—¶é—´</b></td><td>{alert.starts_at.strftime('%Y-%m-%d %H:%M:%S')}</td></tr>
        </table>
        </body>
        </html>
        """

        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = self.from_addr
        msg['To'] = ', '.join(self.to_addrs)
        msg.attach(MIMEText(body, 'html'))

        try:
            with smtplib.SMTP(self.smtp_host, self.smtp_port) as server:
                server.starttls()
                server.login(self.username, self.password)
                server.sendmail(self.from_addr, self.to_addrs, msg.as_string())
            return True
        except Exception as e:
            print(f"Email notification failed: {e}")
            return False


class TelegramChannel(NotificationChannel):
    """Telegram é€šçŸ¥"""

    def __init__(self, bot_token: str, chat_id: str):
        self.bot_token = bot_token
        self.chat_id = chat_id

    def send(self, alert: Alert) -> bool:
        message = f"""ğŸš¨ *çˆ¬è™«å‘Šè­¦*

*è§„åˆ™*: {alert.rule_name}
*çº§åˆ«*: {alert.severity.value}
*æè¿°*: {alert.description}
*æ—¶é—´*: {alert.starts_at.strftime('%Y-%m-%d %H:%M:%S')}
"""

        url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"

        try:
            response = httpx.post(url, data={
                "chat_id": self.chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }, timeout=10)
            return response.status_code == 200
        except Exception as e:
            print(f"Telegram notification failed: {e}")
            return False


# ä½¿ç”¨ç¤ºä¾‹
alert_manager = AlertManager()

# æ·»åŠ è§„åˆ™
for rule in create_default_rules():
    alert_manager.add_rule(rule)

# æ·»åŠ é€šçŸ¥æ¸ é“
dingtalk = DingTalkChannel("https://oapi.dingtalk.com/robot/send?access_token=xxx")
alert_manager.add_handler(dingtalk.send)

# è¯„ä¼°ï¼ˆé€šå¸¸åœ¨å®šæ—¶ä»»åŠ¡ä¸­è°ƒç”¨ï¼‰
metrics = {
    "error_rate": 0.15,
    "queue_size": 5000,
    "avg_response_time": 2.3,
    "available_proxies": 20,
    "active_workers": 5,
}
alert_manager.evaluate(metrics)
```

---

## å¥åº·æ£€æŸ¥

### å¥åº·æ£€æŸ¥æœåŠ¡

```python
"""
å¥åº·æ£€æŸ¥æœåŠ¡
"""

from dataclasses import dataclass, field
from typing import Dict, List, Callable, Any
from enum import Enum
from datetime import datetime
import asyncio
from fastapi import FastAPI
import httpx


class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"


@dataclass
class HealthCheck:
    """å¥åº·æ£€æŸ¥é¡¹"""
    name: str
    check_func: Callable[[], bool]
    timeout: float = 5.0
    critical: bool = True  # æ˜¯å¦å½±å“æ•´ä½“å¥åº·çŠ¶æ€


@dataclass
class HealthResult:
    """å¥åº·æ£€æŸ¥ç»“æœ"""
    name: str
    status: HealthStatus
    message: str = ""
    duration_ms: float = 0
    timestamp: datetime = field(default_factory=datetime.now)


class HealthChecker:
    """å¥åº·æ£€æŸ¥å™¨"""

    def __init__(self):
        self.checks: List[HealthCheck] = []

    def add_check(self, check: HealthCheck):
        """æ·»åŠ æ£€æŸ¥é¡¹"""
        self.checks.append(check)

    async def run_check(self, check: HealthCheck) -> HealthResult:
        """è¿è¡Œå•ä¸ªæ£€æŸ¥"""
        start_time = datetime.now()

        try:
            # å¸¦è¶…æ—¶è¿è¡Œ
            result = await asyncio.wait_for(
                asyncio.to_thread(check.check_func),
                timeout=check.timeout
            )

            duration = (datetime.now() - start_time).total_seconds() * 1000

            if result:
                return HealthResult(
                    name=check.name,
                    status=HealthStatus.HEALTHY,
                    duration_ms=duration
                )
            else:
                return HealthResult(
                    name=check.name,
                    status=HealthStatus.UNHEALTHY,
                    message="Check returned False",
                    duration_ms=duration
                )

        except asyncio.TimeoutError:
            return HealthResult(
                name=check.name,
                status=HealthStatus.UNHEALTHY,
                message=f"Timeout after {check.timeout}s"
            )
        except Exception as e:
            return HealthResult(
                name=check.name,
                status=HealthStatus.UNHEALTHY,
                message=str(e)
            )

    async def run_all(self) -> Dict:
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        results = await asyncio.gather(
            *[self.run_check(c) for c in self.checks]
        )

        # è®¡ç®—æ•´ä½“çŠ¶æ€
        critical_unhealthy = any(
            r.status == HealthStatus.UNHEALTHY
            for r, c in zip(results, self.checks)
            if c.critical
        )

        any_unhealthy = any(r.status == HealthStatus.UNHEALTHY for r in results)

        if critical_unhealthy:
            overall = HealthStatus.UNHEALTHY
        elif any_unhealthy:
            overall = HealthStatus.DEGRADED
        else:
            overall = HealthStatus.HEALTHY

        return {
            "status": overall.value,
            "timestamp": datetime.now().isoformat(),
            "checks": [
                {
                    "name": r.name,
                    "status": r.status.value,
                    "message": r.message,
                    "duration_ms": r.duration_ms,
                }
                for r in results
            ]
        }


# é¢„å®šä¹‰æ£€æŸ¥
def create_default_checks(redis_url: str, mongo_url: str = None) -> List[HealthCheck]:
    """åˆ›å»ºé»˜è®¤æ£€æŸ¥"""

    checks = []

    # Redis æ£€æŸ¥
    def check_redis():
        import redis
        r = redis.from_url(redis_url)
        return r.ping()

    checks.append(HealthCheck(
        name="redis",
        check_func=check_redis,
        timeout=5.0,
        critical=True
    ))

    # MongoDB æ£€æŸ¥
    if mongo_url:
        def check_mongo():
            from pymongo import MongoClient
            client = MongoClient(mongo_url, serverSelectionTimeoutMS=5000)
            return client.admin.command('ping')['ok'] == 1

        checks.append(HealthCheck(
            name="mongodb",
            check_func=check_mongo,
            timeout=5.0,
            critical=True
        ))

    # ä»£ç†æ± æ£€æŸ¥
    def check_proxy_pool():
        import redis
        r = redis.from_url(redis_url)
        count = r.scard("proxy:available")
        return count > 0

    checks.append(HealthCheck(
        name="proxy_pool",
        check_func=check_proxy_pool,
        timeout=5.0,
        critical=False
    ))

    return checks


# FastAPI å¥åº·æ£€æŸ¥ç«¯ç‚¹
app = FastAPI()
checker = HealthChecker()

for check in create_default_checks("redis://localhost:6379"):
    checker.add_check(check)


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    result = await checker.run_all()
    status_code = 200 if result["status"] != "unhealthy" else 503
    return result


@app.get("/health/live")
async def liveness():
    """å­˜æ´»æ¢é’ˆï¼ˆK8sï¼‰"""
    return {"status": "alive"}


@app.get("/health/ready")
async def readiness():
    """å°±ç»ªæ¢é’ˆï¼ˆK8sï¼‰"""
    result = await checker.run_all()
    if result["status"] == "unhealthy":
        return {"status": "not ready"}, 503
    return {"status": "ready"}
```

---

## Grafana ä»ªè¡¨ç›˜

### ä»ªè¡¨ç›˜é…ç½®

```json
{
  "dashboard": {
    "title": "çˆ¬è™«ç›‘æ§ä»ªè¡¨ç›˜",
    "tags": ["crawler", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "title": "è¯·æ±‚é€Ÿç‡",
        "type": "graph",
        "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "rate(crawler_requests_total[5m])",
            "legendFormat": "{{domain}} - {{status_code}}"
          }
        ]
      },
      {
        "title": "é”™è¯¯ç‡",
        "type": "gauge",
        "gridPos": {"x": 12, "y": 0, "w": 6, "h": 8},
        "targets": [
          {
            "expr": "sum(rate(crawler_errors_total[5m])) / sum(rate(crawler_requests_total[5m])) * 100"
          }
        ],
        "options": {
          "thresholds": [
            {"value": 0, "color": "green"},
            {"value": 5, "color": "yellow"},
            {"value": 10, "color": "red"}
          ]
        }
      },
      {
        "title": "é˜Ÿåˆ—é•¿åº¦",
        "type": "stat",
        "gridPos": {"x": 18, "y": 0, "w": 6, "h": 8},
        "targets": [
          {
            "expr": "crawler_queue_size"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´åˆ†å¸ƒ",
        "type": "heatmap",
        "gridPos": {"x": 0, "y": 8, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "rate(crawler_request_duration_seconds_bucket[5m])",
            "format": "heatmap"
          }
        ]
      },
      {
        "title": "æ´»è·ƒ Worker",
        "type": "stat",
        "gridPos": {"x": 12, "y": 8, "w": 6, "h": 8},
        "targets": [
          {
            "expr": "sum(crawler_active_tasks)"
          }
        ]
      },
      {
        "title": "é‡‡é›†æ•°æ®é‡",
        "type": "graph",
        "gridPos": {"x": 18, "y": 8, "w": 6, "h": 8},
        "targets": [
          {
            "expr": "increase(crawler_items_scraped_total[1h])",
            "legendFormat": "{{item_type}}"
          }
        ]
      },
      {
        "title": "ä»£ç†å¥åº·çŠ¶å†µ",
        "type": "table",
        "gridPos": {"x": 0, "y": 16, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "crawler_proxy_requests_total",
            "format": "table"
          }
        ]
      },
      {
        "title": "éªŒè¯ç ç»Ÿè®¡",
        "type": "piechart",
        "gridPos": {"x": 12, "y": 16, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "sum by (captcha_type) (crawler_captcha_total)"
          }
        ]
      }
    ],
    "refresh": "10s"
  }
}
```

### Prometheus å‘Šè­¦è§„åˆ™

```yaml
# prometheus_rules.yml
groups:
  - name: crawler_alerts
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(crawler_errors_total[5m]))
          / sum(rate(crawler_requests_total[5m])) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "çˆ¬è™«é”™è¯¯ç‡è¿‡é«˜"
          description: "é”™è¯¯ç‡å·²è¶…è¿‡ 10%ï¼Œå½“å‰å€¼: {{ $value | humanizePercentage }}"

      - alert: QueueBacklog
        expr: crawler_queue_size > 10000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ä»»åŠ¡é˜Ÿåˆ—ç§¯å‹"
          description: "é˜Ÿåˆ—ä¸­æœ‰ {{ $value }} ä¸ªå¾…å¤„ç†ä»»åŠ¡"

      - alert: SlowResponse
        expr: |
          histogram_quantile(0.95, rate(crawler_request_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å“åº”æ—¶é—´è¿‡é•¿"
          description: "P95 å“åº”æ—¶é—´: {{ $value | humanizeDuration }}"

      - alert: NoActiveWorkers
        expr: sum(crawler_active_tasks) == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "æ²¡æœ‰æ´»è·ƒçš„ Worker"
          description: "æ‰€æœ‰ Worker éƒ½å·²åœæ­¢å·¥ä½œ"

      - alert: ProxyPoolEmpty
        expr: count(crawler_proxy_requests_total{status="success"}) < 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "ä»£ç†æ± å³å°†è€—å°½"
          description: "å¯ç”¨ä»£ç†å°‘äº 5 ä¸ª"

      - alert: HighCaptchaRate
        expr: |
          sum(rate(crawler_captcha_total[5m]))
          / sum(rate(crawler_requests_total[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "éªŒè¯ç å‡ºç°ç‡è¿‡é«˜"
          description: "è¶…è¿‡ 50% çš„è¯·æ±‚è§¦å‘äº†éªŒè¯ç "
```

---

## é“¾è·¯è¿½è¸ª

### OpenTelemetry é›†æˆ

```python
"""
OpenTelemetry é“¾è·¯è¿½è¸ª
"""

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor
from opentelemetry.sdk.resources import Resource
from opentelemetry.semconv.resource import ResourceAttributes
from functools import wraps
from typing import Callable
import httpx


def setup_tracing(service_name: str, jaeger_host: str = "localhost"):
    """è®¾ç½®é“¾è·¯è¿½è¸ª"""

    resource = Resource(attributes={
        ResourceAttributes.SERVICE_NAME: service_name,
    })

    provider = TracerProvider(resource=resource)

    exporter = JaegerExporter(
        agent_host_name=jaeger_host,
        agent_port=6831,
    )

    provider.add_span_processor(BatchSpanProcessor(exporter))
    trace.set_tracer_provider(provider)

    # è‡ªåŠ¨ instrument httpx
    HTTPXClientInstrumentor().instrument()

    return trace.get_tracer(service_name)


# ä½¿ç”¨è£…é¥°å™¨è¿½è¸ª
def traced(name: str = None):
    """è¿½è¸ªè£…é¥°å™¨"""

    def decorator(func: Callable):
        tracer = trace.get_tracer(__name__)

        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            span_name = name or func.__name__
            with tracer.start_as_current_span(span_name) as span:
                # æ·»åŠ å±æ€§
                span.set_attribute("function", func.__name__)

                try:
                    result = await func(*args, **kwargs)
                    span.set_attribute("success", True)
                    return result
                except Exception as e:
                    span.set_attribute("success", False)
                    span.set_attribute("error", str(e))
                    span.record_exception(e)
                    raise

        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            span_name = name or func.__name__
            with tracer.start_as_current_span(span_name) as span:
                try:
                    result = func(*args, **kwargs)
                    span.set_attribute("success", True)
                    return result
                except Exception as e:
                    span.set_attribute("success", False)
                    span.record_exception(e)
                    raise

        if asyncio.iscoroutinefunction(func):
            return async_wrapper
        return sync_wrapper

    return decorator


# ä½¿ç”¨ç¤ºä¾‹
tracer = setup_tracing("crawler-service", "localhost")


@traced("crawl_page")
async def crawl_page(url: str):
    """å¸¦è¿½è¸ªçš„çˆ¬å–"""
    current_span = trace.get_current_span()
    current_span.set_attribute("url", url)

    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        current_span.set_attribute("status_code", response.status_code)
        return response


@traced("parse_data")
def parse_data(html: str):
    """å¸¦è¿½è¸ªçš„è§£æ"""
    current_span = trace.get_current_span()
    # è§£æé€»è¾‘...
    current_span.set_attribute("items_found", 10)
    return []
```

---

## è¯Šæ–­æ—¥å¿—

```
# æŒ‡æ ‡é‡‡é›†
[METRICS] é‡‡é›†å‘¨æœŸ: {interval}s
[METRICS] è¯·æ±‚æ€»é‡: {requests_total}, é”™è¯¯: {errors_total}
[METRICS] å¹³å‡å»¶è¿Ÿ: {avg_latency}ms, P99: {p99_latency}ms
[METRICS] é˜Ÿåˆ—é•¿åº¦: {queue_size}
[METRICS] æ´»è·ƒWorker: {active_workers}

# å‘Šè­¦è§¦å‘
[ALERT] è§„åˆ™è§¦å‘: {rule_name}
[ALERT] çº§åˆ«: {severity}, æè¿°: {description}
[ALERT] å½“å‰å€¼: {current_value}, é˜ˆå€¼: {threshold}
[ALERT] é€šçŸ¥æ¸ é“: {channels}

# å‘Šè­¦æ¢å¤
[ALERT] è§„åˆ™æ¢å¤: {rule_name}
[ALERT] æŒç»­æ—¶é—´: {duration}

# æ—¥å¿—èšåˆ
[LOG] æ¨é€åˆ°Loki: {batch_size}æ¡
[LOG] æ—¥å¿—çº§åˆ«åˆ†å¸ƒ: INFO={info}, WARN={warn}, ERROR={error}

# å¥åº·æ£€æŸ¥
[HEALTH] æ£€æŸ¥é¡¹: {check_name}
[HEALTH] çŠ¶æ€: {status}, è€—æ—¶: {duration}ms
[HEALTH] æ•´ä½“çŠ¶æ€: {overall_status}

# é“¾è·¯è¿½è¸ª
[TRACE] TraceID: {trace_id}
[TRACE] Span: {span_name}, è€—æ—¶: {duration}ms
[TRACE] è°ƒç”¨é“¾æ·±åº¦: {depth}

# é€šçŸ¥å‘é€
[NOTIFY] æ¸ é“: {channel} (é’‰é’‰/é£ä¹¦/é‚®ä»¶)
[NOTIFY] å‘é€ç»“æœ: {success}

# é”™è¯¯æƒ…å†µ
[METRICS] ERROR: æŒ‡æ ‡é‡‡é›†å¤±è´¥: {error}
[ALERT] ERROR: é€šçŸ¥å‘é€å¤±è´¥: {channel}, {error}
[HEALTH] ERROR: å¥åº·æ£€æŸ¥è¶…æ—¶: {check_name}
```

---

## ç­–ç•¥åè°ƒ

ç›‘æ§å‘Šè­¦é…åˆ [16-æˆ˜æœ¯å†³ç­–æ¨¡å—](16-tactics.md) å®ç°è‡ªåŠ¨å“åº”ï¼š
- **é”™è¯¯ç‡å‘Šè­¦** â†’ è‡ªåŠ¨åˆ‡æ¢ä»£ç†/é™ä½å¹¶å‘
- **é˜Ÿåˆ—ç§¯å‹å‘Šè­¦** â†’ è‡ªåŠ¨æ‰©å®¹ Worker
- **ä»£ç†è€—å°½å‘Šè­¦** â†’ è‡ªåŠ¨è§¦å‘ä»£ç†è¡¥å……

---

## ç›¸å…³æ¨¡å—

- **ä¸Šæ¸¸**: [08-è¯Šæ–­æ¨¡å—](08-diagnosis.md) - é”™è¯¯è¯Šæ–­
- **é…åˆ**: [13-åˆ†å¸ƒå¼æ¨¡å—](13-distributed.md) - é›†ç¾¤ç›‘æ§
- **é…åˆ**: [07-è°ƒåº¦æ¨¡å—](07-scheduling.md) - ä»»åŠ¡ç›‘æ§
- **è¾“å‡º**: [17-åé¦ˆé—­ç¯æ¨¡å—](17-feedback-loop.md) - æŒ‡æ ‡åé¦ˆä¸è‡ªåŠ¨è°ƒèŠ‚

---

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•é€‰æ‹©ç›‘æ§æ–¹æ¡ˆï¼Ÿ

| è§„æ¨¡ | æ¨èæ–¹æ¡ˆ |
|-----|---------|
| å°å‹ï¼ˆå•æœºï¼‰ | æ—¥å¿—æ–‡ä»¶ + ç®€å•è„šæœ¬ |
| ä¸­å‹ï¼ˆé›†ç¾¤ï¼‰ | Prometheus + Grafana |
| å¤§å‹ï¼ˆåˆ†å¸ƒå¼ï¼‰ | Prometheus + Loki + Jaeger |

### Q: å‘Šè­¦ç–²åŠ³å¦‚ä½•å¤„ç†ï¼Ÿ

1. è®¾ç½®åˆç†çš„é˜ˆå€¼å’Œå†·å´æ—¶é—´
2. ä½¿ç”¨å‘Šè­¦åˆ†çº§ï¼Œåªå¯¹ CRITICAL å‘é€å³æ—¶é€šçŸ¥
3. å®ç°å‘Šè­¦èšåˆï¼Œç›¸ä¼¼å‘Šè­¦åˆå¹¶
4. å®šæœŸå›é¡¾å’Œè°ƒæ•´å‘Šè­¦è§„åˆ™

### Q: æ—¥å¿—é‡å¤ªå¤§å¦‚ä½•å¤„ç†ï¼Ÿ

1. è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œç”Ÿäº§ç¯å¢ƒç”¨ WARNING åŠä»¥ä¸Š
2. é‡‡æ ·æ—¥å¿—ï¼Œåªè®°å½•éƒ¨åˆ†è¯·æ±‚
3. ä½¿ç”¨æ—¥å¿—è½®è½¬ï¼Œè‡ªåŠ¨æ¸…ç†æ—§æ—¥å¿—
4. ç»“æ„åŒ–æ—¥å¿—ï¼Œä¾¿äºè¿‡æ»¤å’Œåˆ†æ
